{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Summarizing and Querying Videos using Gemini and RAG","metadata":{}},{"cell_type":"markdown","source":"This notebook was created as a capstone project to the [5-Day Gen AI Intensive Course with Google](https://www.kaggle.com/learn-guide/5-day-genai). Some of the code in the RAG section is taken from the corresponding notebooks.\n\nWe will analyze recent YouTube videos (uploaded within the last 24 hours) about AI, and perform the following tasks:\n\n* Understanding of video content and transcripts.\n* Provision of both free-form and structured responses (JSON and other).\n* Retrieval-Augmented Generation (RAG): Vectorisation of the video transcripts with ChromaDB to be used for Gemini queries.\n\nWe first remove packages that create conflict and install the relevant ones.","metadata":{},"attachments":{}},{"cell_type":"code","source":"# Remove unused conflicting packages\n!pip uninstall -qqy jupyterlab jupyterlab-lsp google-cloud-translate google-spark-connect pandas-gbq bigframes google-cloud-bigtable protobuf google-cloud-automl gcsfs\n# Install relevant packages\n!pip install -qU google-api-core\n!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n!pip install -qU youtube_transcript_api","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:20:25.977880Z","iopub.execute_input":"2025-05-18T19:20:25.978111Z","iopub.status.idle":"2025-05-18T19:21:34.902405Z","shell.execute_reply.started":"2025-05-18T19:20:25.978093Z","shell.execute_reply":"2025-05-18T19:21:34.901158Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"We now import the main packages that will be used subsequently.","metadata":{}},{"cell_type":"code","source":"from googleapiclient.discovery import build\nfrom youtube_transcript_api import YouTubeTranscriptApi\nfrom datetime import datetime, timedelta, timezone\nimport os\nfrom kaggle_secrets import UserSecretsClient\nfrom google import genai\nfrom google.genai import types\nfrom IPython.display import HTML, Markdown, display\nfrom google.api_core import retry","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:36.932026Z","iopub.execute_input":"2025-05-18T19:24:36.932894Z","iopub.status.idle":"2025-05-18T19:24:39.582974Z","shell.execute_reply.started":"2025-05-18T19:24:36.932779Z","shell.execute_reply":"2025-05-18T19:24:39.581970Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"We also need to create API keys for Gemini and Youtube, and then retrieve them as secrets so that they are not publicly visible.","metadata":{}},{"cell_type":"code","source":"GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nYOUTUBE_API_KEY = UserSecretsClient().get_secret(\"YOUTUBE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:39.584686Z","iopub.execute_input":"2025-05-18T19:24:39.585555Z","iopub.status.idle":"2025-05-18T19:24:39.858016Z","shell.execute_reply.started":"2025-05-18T19:24:39.585528Z","shell.execute_reply":"2025-05-18T19:24:39.856955Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"We set up a helper function to decide whether to retry an API call specifically when a per-minute quota (429 error) or a service unavailability issue (503 error) is encountered within the context of the genai library. ","metadata":{}},{"cell_type":"code","source":"is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:39.859048Z","iopub.execute_input":"2025-05-18T19:24:39.859392Z","iopub.status.idle":"2025-05-18T19:24:39.864743Z","shell.execute_reply.started":"2025-05-18T19:24:39.859366Z","shell.execute_reply":"2025-05-18T19:24:39.863948Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 1. Search and Summarise using the Youtube API\n\n### 1.2 Defining the required functions\n\nThe following function searches YouTube for the newest videos about a specific topic. It connects to YouTube and searches for videos uploaded within the last day, ordered by upload date. It checks that the videos they have English subtitles available. If a video meets these criteria, the algorithm collects its title, the name of the channel that posted it, and its YouTube ID. Finally, it returns a list containing this information.","metadata":{},"attachments":{}},{"cell_type":"code","source":"@retry.Retry(predicate=is_retriable)\ndef get_latest_videos(query, max_results=10, num_return=5):\n    \"\"\"\n    Searches YouTube for the latest videos on a given subject and returns a list of their title, channel, ID.\n\n    Args:\n        query (str): The search term.\n        max_results (int): The maximum number of videos to retrieve.\n        num_return (int): The intended number of video info to return.\n\n    Returns:\n        info list[dict]: Each dictionary contains a YouTube video title, channel, and ID.\n    \"\"\"\n    youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n    now_time = datetime.now(timezone.utc)\n    published_after = now_time - timedelta(days=1)\n\n    try:\n        search_response = youtube.search().list(\n            part='id,snippet',\n            q=query,\n            type='video',\n            order='date',\n            relevanceLanguage='en',\n            safeSearch='strict',\n            videoDuration='medium',\n            videoCaption='closedCaption',\n            maxResults=max_results,\n            publishedAfter=published_after.isoformat()\n        ).execute()\n\n        info = []\n        counter = 0\n        for item in search_response['items']:\n            if counter == num_return:\n                break\n\n            # eliminate videos that set to premier later\n            if item['snippet']['liveBroadcastContent'] == 'none' and item['id']['kind'] == 'youtube#video':\n                caption_response = youtube.captions().list(part='snippet', videoId=item['id']['videoId']).execute()\n                \n                # check the existence of english captions\n                en_flag = False\n                if caption_response and 'items' in caption_response:\n                    for track in caption_response['items']:\n                        language = track['snippet'].get('language')\n                        if language == 'en':\n                            en_flag = True\n                            break\n                if en_flag == True:\n                    info.append({'title': item['snippet']['title'], 'channel':item['snippet']['channelTitle'], 'id': item['id']['videoId']})\n                    counter+=1\n                       \n        return info\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        return []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:39.866014Z","iopub.execute_input":"2025-05-18T19:24:39.866337Z","iopub.status.idle":"2025-05-18T19:24:39.892965Z","shell.execute_reply.started":"2025-05-18T19:24:39.866313Z","shell.execute_reply":"2025-05-18T19:24:39.891930Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"To retrieve the transcripts after the video IDs are retrieved, we define another function that also processes them into continuous text.","metadata":{}},{"cell_type":"code","source":"def fetch_pro(info):\n    \"\"\"\n    Searches for YouTube transcripts of given video IDs\n\n    Args:\n        info (list[dict]): list of dictionaries that contain title, channel, ID of youtube videos\n\n    Returns:\n        all_transcripts (list[str]): list of transcripts\n    \"\"\"\n    ytt_api = YouTubeTranscriptApi()\n    all_transcripts = []\n    for item in info:\n        try:\n            fetched_transcript = ytt_api.fetch(item['id'], languages=['en'])\n        \n            transcript = 'TRANSCRIPT: '\n            for snippet in fetched_transcript:\n                transcript = transcript + snippet.text + ' '\n        \n            transcript = transcript.replace('$', '&#36;') # replaces $ with html symbol, so that it's not seen as LaTeX by Markdown.\n            all_transcripts.append(transcript)\n        except Exception as e:\n            print(f\"Error fetching transcript for video ID {item['id']}: {e}\")\n    return all_transcripts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:39.895451Z","iopub.execute_input":"2025-05-18T19:24:39.895808Z","iopub.status.idle":"2025-05-18T19:24:39.918073Z","shell.execute_reply.started":"2025-05-18T19:24:39.895771Z","shell.execute_reply":"2025-05-18T19:24:39.916945Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"After obtaining the video transcripts, we will ask Gemini to summarise the contents of these videos in one paragraph each. We will ask it to output the result in **json** form so that we can easily find and display its parts (title, channel, summary) at will.","metadata":{}},{"cell_type":"code","source":"import typing_extensions as typing\nimport json\n\nclass VideoSum(typing.TypedDict):\n    TITLE: str\n    CHANNEL: str\n    SUMMARY: str\n\n@retry.Retry(predicate=is_retriable)\ndef summarise_text(question, header, text):\n    \"\"\"\n    Receives a question on a text and returns the reply of Gemini in json form.\n\n    Args:\n        question (str): The question being asked.\n        header (str): The header of the text.\n        text (str): The text on which the question is asked.\n      \n    \"\"\"\n    client = genai.Client(api_key=GOOGLE_API_KEY)\n    config = types.GenerateContentConfig(temperature=0.0,response_mime_type=\"application/json\",\n        response_schema=VideoSum)\n    response = client.models.generate_content(\n        model='gemini-2.0-flash',\n        config=config,\n        contents=[request, header, text],\n        )\n\n    return response.text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:39.919600Z","iopub.execute_input":"2025-05-18T19:24:39.919923Z","iopub.status.idle":"2025-05-18T19:24:39.943929Z","shell.execute_reply.started":"2025-05-18T19:24:39.919889Z","shell.execute_reply":"2025-05-18T19:24:39.942946Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### 1.2 Calling the above functions and asking questions on the retrieved videos \nWe will search for the latest videos about artificial intelligence and print their titles, along with their channel and ID. Note that we are searching for videos that have english captions, but the video's title might be in a different language than english. This is not a problem since we can ask Gemini to translate it.","metadata":{}},{"cell_type":"code","source":"info = get_latest_videos('artificial intelligence', max_results=10, num_return=5)\n\n#We take a look at the result\nfor item in info:\n    display(Markdown(f\"TITLE: {item['title']}, CHANNEL: {item['channel']}, ID: {item['id']}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:39.944799Z","iopub.execute_input":"2025-05-18T19:24:39.945235Z","iopub.status.idle":"2025-05-18T19:24:41.306563Z","shell.execute_reply.started":"2025-05-18T19:24:39.945192Z","shell.execute_reply":"2025-05-18T19:24:41.305668Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: Use this prompt to learn from podcast quick with AI (NotebookLM tutorial), CHANNEL: Ahead Of The Curve Artificial Intelligence, ID: xcbjTXOqsiY"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: AI Debates CAPITALISM vs COMMUNISM, CHANNEL: Elite Questions, ID: VRali-H9g9M"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: AI Civil War: DeepSeek-V3-0324 vs Claude 3.7 Sonnet - Which is Best?, CHANNEL: AI Perspectives, ID: mlCDhMyKedI"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: Create AMAZING Branded Materials in Minutes with This Easy Guide, CHANNEL: AI Communication AI Clarity Strategies, ID: 3fjCCrBH7JI"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: [ ENG SUB] AI for Beginners 2025: Learn Artificial Intelligence from Scratch (Step-by-Step Guide), CHANNEL: Toni Kusworo Tutorial, ID: GUolwsTnV7s"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"We now fetch the transcripts of the retrieved videos.","metadata":{}},{"cell_type":"code","source":"all_transcripts = fetch_pro(info)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:41.307764Z","iopub.execute_input":"2025-05-18T19:24:41.308150Z","iopub.status.idle":"2025-05-18T19:24:45.068931Z","shell.execute_reply.started":"2025-05-18T19:24:41.308127Z","shell.execute_reply":"2025-05-18T19:24:45.068094Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"We can finally ask Gemini to summarise the content of the video transcripts.","metadata":{}},{"cell_type":"code","source":"request = \"\"\"\nCan you summarise the transcript in one paragraph? If the title or the name of the channel are not in english, then translate it in english.\n\"\"\"\n\nheader = \"\"\"\nTITLE: {}\nCHANNEL: {}\n\"\"\"\n\nfor index, item in enumerate(info):\n    summary = json.loads(summarise_text(request, header.format(item['title'], item['channel']), all_transcripts[index]))\n    display(Markdown(f\"TITLE: {summary['TITLE']}<br>CHANNEL: {summary['CHANNEL']}<br>SUMMARY: {summary['SUMMARY']}\"))\n    print('-'*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:45.069904Z","iopub.execute_input":"2025-05-18T19:24:45.070180Z","iopub.status.idle":"2025-05-18T19:24:53.949045Z","shell.execute_reply.started":"2025-05-18T19:24:45.070157Z","shell.execute_reply":"2025-05-18T19:24:53.947754Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: Use this prompt to learn from podcast quick with AI (NotebookLM tutorial)<br>CHANNEL: Ahead Of The Curve Artificial Intelligence<br>SUMMARY: This video tutorial by Ahead Of The Curve Artificial Intelligence demonstrates how to use Google's NotebookLM to quickly learn from podcasts. The tutorial explains how to upload a podcast as a source, use the AI to summarize the content and create a 'deep dive' podcast, and then use a specific prompt to identify and list the major sections of the podcast. This allows users to jump directly to the sections of interest, saving time compared to listening to the entire podcast. The presenter emphasizes the efficiency of this method for targeted learning and encourages viewers to subscribe, share, like, and comment."},"metadata":{}},{"name":"stdout","text":"--------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: AI Debates CAPITALISM vs COMMUNISM<br>CHANNEL: Elite Questions<br>SUMMARY: In a debate hosted by Elite Questions, two AI models argue the merits of capitalism versus communism. The capitalist AI champions freedom, innovation, and individual opportunity, acknowledging the need for regulation to prevent abuse, while the communist AI critiques capitalism for entrenching inequality, prioritizing profit over people, and commodifying basic needs. The debate touches on historical examples, ethical considerations, and potential solutions, ultimately concluding without a simple answer, emphasizing the need for continued conversation and inviting audience input for future discussions."},"metadata":{}},{"name":"stdout","text":"--------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: AI Civil War: DeepSeek-V3-0324 vs Claude 3.7 Sonnet - Which is Best?<br>CHANNEL: AI Perspectives<br>SUMMARY: In a rapidly evolving AI landscape, AI Perspectives compares Deepseek V3 0324, a cost-effective and open-source friendly model strong in coding, against Claude 3.7 Sonnet from Anthropic, a top-tier generalist known for superior reasoning, a large context window, and multimodal capabilities. Deepseek V3 0324 excels in coding tasks and offers cost savings, while Claude 3.7 Sonnet shines in complex reasoning, handling large contexts, and image analysis. The choice depends on specific needs: Deepseek for efficient coding and open-source flexibility, and Claude for deep reasoning, extensive information processing, and image analysis, ultimately driving AI innovation."},"metadata":{}},{"name":"stdout","text":"--------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: Create AMAZING Branded Materials in Minutes with This Easy Guide<br>CHANNEL: AI Communication AI Clarity Strategies<br>SUMMARY: Stefan Arbeck, the founder of Just That Simple, introduces a channel focused on leveraging AI tools to solve business problems through training videos. The channel aims to provide quick and simple strategies for various business challenges by demonstrating how to use AI tools effectively. A teaser video showcases how AI can streamline event planning, from brainstorming themes with ChatGPT to automating tasks with Notion AI and creating promotional materials with Canva and Runway, promising a faster, smarter, and more scalable approach to event management."},"metadata":{}},{"name":"stdout","text":"--------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"TITLE: AI for Beginners 2025: Learn Artificial Intelligence from Scratch (Step-by-Step Guide)<br>CHANNEL: Toni Kusworo Tutorial<br>SUMMARY: Toni Kusworo's tutorial, \"AI for Beginners 2025,\" guides viewers on learning AI from scratch, starting with understanding the concept of 'prompt' as a command given to AI. The tutorial emphasizes creating detailed prompts with specific subjects, actions, styles, and additional details to achieve desired results, providing examples of visual styles like realistic, anime, 3D, painting, and fantasy. It demonstrates using prompts in both GPT chat and Meta AI on WhatsApp to generate images, further illustrating how to animate these images using Pixverse AI, including instructions on uploading, prompting for animation, and downloading the final video."},"metadata":{}},{"name":"stdout","text":"--------------------\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"We can also make more general questions.","metadata":{}},{"cell_type":"code","source":"prompt = 'According to the transcripts, what is currently trending in AI? Give a short answer.'\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents=[prompt, all_transcripts])\n\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:53.950086Z","iopub.execute_input":"2025-05-18T19:24:53.950462Z","iopub.status.idle":"2025-05-18T19:24:55.909361Z","shell.execute_reply.started":"2025-05-18T19:24:53.950420Z","shell.execute_reply":"2025-05-18T19:24:55.908411Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Based on the transcripts, current trends in AI include:\n\n*   **AI-powered tools for learning and note-taking:** Using AI (like Notebook LM) to summarize and analyze podcasts and other learning materials.\n*   **AI ideological debates:** Using AI to simulate debates on complex topics like capitalism versus communism.\n*   **Competition between advanced language models:** Deepseek V3 and Claude 3 are competing.\n*   **AI in solving business problems:** Utilizing AI tools for specific business tasks like event planning.\n*   **AI Image Generation and Animation:** Techniques and tools to generate and animate images using AI."},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"We'll now force Gemini to give a one-word answer: YES or NO, to a rather hard question, given the retrieved transcripts.","metadata":{}},{"cell_type":"code","source":"import enum\n\nprompt = 'Is AI going to rule the world?'\n\nclass Sentiment(enum.Enum):\n    YES = \"YES\"\n    NO = \"NO\"\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=types.GenerateContentConfig(\n        response_mime_type=\"text/x.enum\",\n        response_schema=Sentiment\n    ),\n    contents=[prompt, all_transcripts])\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:55.911674Z","iopub.execute_input":"2025-05-18T19:24:55.912030Z","iopub.status.idle":"2025-05-18T19:24:56.548278Z","shell.execute_reply.started":"2025-05-18T19:24:55.912003Z","shell.execute_reply":"2025-05-18T19:24:56.547280Z"}},"outputs":[{"name":"stdout","text":"NO\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## 1.3 Retrieval Augmented Generation with Chroma","metadata":{}},{"cell_type":"markdown","source":"Hopefully the retrieved transcripts are of high quality and new information, so we'd like Gemini to have easy access to them. This code defines a custom embedding function, for use with ChromaDB. It uses Google's Gemini API to generate those embeddings. ","metadata":{}},{"cell_type":"code","source":"import chromadb\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\nfrom google.api_core import retry\n\nfrom google.genai import types\n\n\n# Define a helper to retry when per-minute quota is reached.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    # Specify whether to generate embeddings for documents, or queries\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:56.549518Z","iopub.execute_input":"2025-05-18T19:24:56.549964Z","iopub.status.idle":"2025-05-18T19:24:57.325142Z","shell.execute_reply.started":"2025-05-18T19:24:56.549930Z","shell.execute_reply":"2025-05-18T19:24:57.324204Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"We now set up a ChromaDB vector database and generate embeddings for the retrieved transcripts, which are added to the database.","metadata":{}},{"cell_type":"code","source":"DB_NAME = \"youtube_transcripts\"\n\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n\ndb.add(documents=all_transcripts, ids=[str(i) for i in range(len(all_transcripts))])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:24:57.326275Z","iopub.execute_input":"2025-05-18T19:24:57.326639Z","iopub.status.idle":"2025-05-18T19:24:58.083152Z","shell.execute_reply.started":"2025-05-18T19:24:57.326609Z","shell.execute_reply":"2025-05-18T19:24:58.082110Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"The following code performs a semantic search on the ChromaDB database, searching for information related to the query \"What is new in AI?\". ","metadata":{}},{"cell_type":"code","source":"embed_fn.document_mode = False # Switch to query mode when generating embeddings.\nquery = \"What is new in AI?\"\n\nresult = db.query(query_texts=[query], n_results=1)\n[all_passages] = result[\"documents\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:38:15.645518Z","iopub.execute_input":"2025-05-18T19:38:15.645815Z","iopub.status.idle":"2025-05-18T19:38:16.029138Z","shell.execute_reply.started":"2025-05-18T19:38:15.645795Z","shell.execute_reply":"2025-05-18T19:38:16.027947Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"We now construct the prompt, based on the passages retrieved. ","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"You are a helpful and informative bot that answers questions in detail using text from the reference passage included below. \nIf the passage is irrelevant to the answer, you may ignore it.\n\nQUESTION: {query}\n\"\"\"\n\n# Add the retrieved documents to the prompt.\nfor passage in all_passages:\n    passage_oneline = passage.replace(\"\\n\", \" \")\n    prompt += f\"PASSAGE: {passage_oneline}\\n\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:38:41.040447Z","iopub.execute_input":"2025-05-18T19:38:41.040792Z","iopub.status.idle":"2025-05-18T19:38:41.046186Z","shell.execute_reply.started":"2025-05-18T19:38:41.040766Z","shell.execute_reply":"2025-05-18T19:38:41.045154Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"We finally make our question: \"What is new in AI?\", according to the retrieved youtube video transcripts.","metadata":{}},{"cell_type":"code","source":"answer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt)\n\nMarkdown(answer.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T19:38:42.472249Z","iopub.execute_input":"2025-05-18T19:38:42.473239Z","iopub.status.idle":"2025-05-18T19:38:44.020604Z","shell.execute_reply.started":"2025-05-18T19:38:42.473205Z","shell.execute_reply":"2025-05-18T19:38:44.019632Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"According to the passage, the AI use case no one is talking about is AI's role in how we interact socially and what that might mean for all of us. It mentions a fascinating interview with Reid Hoffman, co-founder of LinkedIn, who comes at it from this angle. The true killer app of AI will be multiplayer social, not just single-payer chatbots like ChatGPT. Within a few years, we are likely to be in a surrounding field of agents. These agents won't just be for individual use, but will mediate interactions between individuals, groups, and societies. They will make the currently more invisible networks we live in more mediated. For example, having agents listen during conversation and potentially offering corrections or additional information like mentioning a philosopher relevant to the discussion. These agents would be in the field around us and could be socially aware.\n"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}